#!/usr/bin/env python
from argparse import ArgumentParser
import os
import sys
import shutil
from commands import getstatusoutput
from os.path import basename, dirname, abspath, exists, realpath
from yaml import safe_load
from os import makedirs, unlink
from hashlib import sha1
from glob import glob
import subprocess
from os import readlink
import logging
from logging import debug,error
import time

def format(s, **kwds):
  return s % kwds

def star():
  return basename(sys.argv[0]).replace("Build", "")

def gzip():
  err, out = getstatusoutput("which pigz")
  if err:
    return "gzip"
  return "pigz"

def execute(command, printer=debug):
  popen = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)
  lines_iterator = iter(popen.stdout.readline, "")
  for line in lines_iterator:
    debug(line.strip("\n"))  # yield line
  output = popen.communicate()[0]
  debug(output)
  exitCode = popen.returncode
  return exitCode

def updateReferenceRepos(referenceSources, buildOrder, specs):
  # Update source reference area, if possible.
  # If the area is already there and cannot be written, assume it maintained
  # by someone else.
  #
  # If the area can be created, clone a bare repository with the sources.
  debug("Updating references.")
  for p in buildOrder:
    spec = specs[p]
    referenceRepo = "%s/%s" % (abspath(referenceSources), p.lower()) 
    if os.access(dirname(referenceSources), os.W_OK):
      getstatusoutput("mkdir -p %s" % referenceSources)
    writeableReference = os.access(referenceSources, os.W_OK)
    if not writeableReference and exists(referenceRepo):
      debug("Using %s as reference for %s." % (referenceRepo, p))
      spec["reference"] = referenceRepo
      continue
    if not writeableReference:
      debug("Cannot create reference for %s in specified folder.", p)
      continue
    
    err, out = getstatusoutput("mkdir -p %s" % abspath(referenceSources))
    if not "source" in spec:
      continue
    if not exists(referenceRepo):
      cmd = ["git", "clone", "--bare", spec["source"], referenceRepo]
      debug(" ".join(cmd))
      err = execute(" ".join(cmd))
    else:
      err = execute(format("cd %(referenceRepo)s && "
                           "git fetch --tags %(source)s 2>&1 && "
                           "git fetch %(source)s 2>&1",
                           referenceRepo=referenceRepo,
                           source=spec["source"]))
    if err:
      print "Error while updating reference repos %s." % spec["source"] 
      sys.exit(1)
    spec["reference"] = referenceRepo

def getDirectoryHash(d):
  err, out = getstatusoutput("GIT_DIR=%s/.git git show-ref HEAD | cut -f1 -d\ " % d)
  if err:
    print "Impossible to find reference for %s " % d 
    sys.exit(0)
  return out

if __name__ == "__main__":
  parser = ArgumentParser()
  parser.add_argument("action")
  parser.add_argument("pkgname")
  parser.add_argument("--config-dir", "-c", dest="configDir", default="%sdist" % star())
  parser.add_argument("--work-dir", "-w", dest="workDir", default="sw")
  parser.add_argument("--architecture", "-a", dest="architecture", required=True)
  parser.add_argument("--jobs", "-j", dest="jobs", default=1)
  parser.add_argument("--reference-sources", dest="referenceSources", default="sw/MIRROR")
  parser.add_argument("--debug", "-d", dest="debug", action="store_true", default=False)
  args = parser.parse_args()
  
  logger = logging.getLogger()
  logger_handler = logging.StreamHandler()
  logger.addHandler(logger_handler)

  if args.debug:
    logger.setLevel(logging.DEBUG)
    logger_handler.setFormatter(logging.Formatter('%(levelname)s: %(message)s'))
  else:
    logger.setLevel(logging.INFO)

  # Setup build environment.
  if not args.action == "build":
    parser.error("Action %s unsupported" % args.action)
  packages = [args.pkgname]
  specs = {}
  buildOrder = []
  workDir = abspath(args.workDir)
  specDir = "%s/SPECS" % workDir
  if not exists(specDir):
    makedirs(specDir)

  debug(format("Using %(star)sBuild from "
               "%(star)sbuild@%(toolHash)s recipes "
               "in %(star)sdist@%(distHash)s",
               star=star(),
               toolHash=getDirectoryHash(dirname(__file__)),
               distHash=getDirectoryHash(args.configDir)))

  while packages:
    p = packages.pop(0)
    if p in specs:
      buildOrder.remove(p)
      buildOrder.insert(0, p)
      continue
    try:
      d = open("%s/%s.sh" % (args.configDir, p.lower())).read()
    except IOError,e:
      print e
      sys.exit(1)
    header, recipe = d.split("---", 1)
    spec = safe_load(header)
    # Check that version is a string
    if not isinstance(spec["version"], basestring):
      print "In recipe \"%s\": version must be a string" % p
      sys.exit(1)
    spec["tag"] = spec.get("tag", spec["version"])
    spec["recipe"] = recipe.strip("\n")
    specs[p] = spec 
    buildOrder.insert(0, p)
    packages += spec.get('requires', [])
    open("%s/SPECS/%s.sh" % (workDir, spec["package"]), "w").write(spec["recipe"])

  # Resolve the tag to the actual commit ref, so that 
  for p in buildOrder:
    spec = specs[p]
    spec["commit_hash"] = "0"
    if "source" in spec:
      cmd = format("git ls-remote --heads %(source)s",
                   source = spec["source"])
      err, out = getstatusoutput(cmd)
      if err:
        print "Unable to fetch from %s" % spec["source"]
        sys.exit(1)
      # by default we assume tag is a commit hash
      spec["commit_hash"] = spec["tag"]
      for l in out.split("\n"):
        if l.endswith("refs/heads/%s" % spec["tag"]):
          spec["commit_hash"] = l.split("\t", 1)[0]
          break

  # Decide what is the main package we are building and at what commit.
  #
  # We emit an event for the main package, when encountered, so that we can use
  # it to index builds of the same hash on different architectures. We also
  # make sure add the main package and it's hash to the debug log, so that we
  # can always extract it from it.
  # If one of the special packages is in the list of packages to be built,
  # we use it as main package, rather than the last one.
  mainPackage = None
  mainHash = None
  for p in buildOrder:
    spec = specs[p]
    mainPackage = p
    mainHash = spec["commit_hash"]
    if p.lower() in ["aliroot", "aliphysics", "o2"]:
      break
  debug("Main package is %s@%s" % (mainPackage, mainHash))
  if args.debug:
    logger_handler.setFormatter(
        logging.Formatter("%%(levelname)s:%s:%s: %%(message)s" % 
                          (mainPackage, mainHash[0:8])))

  # Now that we have the main package set, we can print out Useful information
  # which we will be able to associate with this build.
  for p in buildOrder:
    spec = specs[p]
    if "source" in spec:
      debug("Commit hash for %s@%s is %s" % (spec["source"], spec["tag"], spec["commit_hash"]))

  # Calculate the hashes. We do this in build order so that we can guarantee
  # that the hashes of the dependencies are calculated first.  Also notice that
  # if the commit hash is a real hash, and not a tag, we can safely assume
  # that's unique, and therefore we can avoid putting the repository or the
  # name of the branch in the hash.
  debug("Calculating hashes.")
  for p in buildOrder:
    spec = specs[p]
    h = sha1(spec["recipe"])
    h.update(spec["version"])
    h.update(spec["package"])
    h.update(spec["commit_hash"])
    if spec["commit_hash"] == spec.get("tag", "0"):
      h.update(spec.get("source", "none"))
      if "source" in spec:
        h.update(spec["tag"])
    h.update(str(spec.get("env", {})))
    h.update(str(spec.get("append_path", {})))
    h.update(str(spec.get("prepend_path", {})))
    requires = spec.get("requires", [])
    for dep in requires:
      h.update(specs[dep]["hash"])
    if bool(spec.get("force_rebuild", False)):
      h.update(str(time.time()))
    hash = h.hexdigest()
    spec["hash"] = hash
    debug("Hash for recipe %s.sh is %s" % (p, hash))
  
  # Decide how it should be called, based on the hash and what is already
  # available
  # FIXME: check in the repository as well and download tarball if already
  #        build
  debug("Checking for packages already built.")
  newBuildOrder = []
  for p in buildOrder:
    spec = specs[p]
    installations = glob("%s/%s/%s/*" % (workDir, args.architecture, p))
    # In case there is no installed software, revision is 1
    # If there is already an installed package:
    # - Remove it if we do not know its hash
    # - Use the latest number in the version, to decide its revision
    debug(installations)
    if not installations:
      spec["revision"] = 1
      newBuildOrder.append(p)
      continue
    busyRevisions = []
    for d in installations:
      hashFile = "%s/.build-hash" % d
      if not exists(hashFile):
        shutil.rmtree("%s" % d)
      version = basename(d)
      assert("-" in version)
      revision = int(version.rsplit("-")[-1])
      h = open(hashFile).read().strip("\n")
      # If we have an hash match, we use the old revision for the package
      # and we do not need to build it.
      if h == spec["hash"]:
        print "Package %s with hash %s is already found in %s. Not building." % (p, h, d)
        spec["revision"] = revision
      else:
        busyRevisions.append(revision)
    if not "revision" in spec:
      spec["revision"] = min(set(range(1, max(busyRevisions)+2)) - set(busyRevisions))
      newBuildOrder.append(p)
  buildOrder = newBuildOrder
  
  # If the software already exists as a tarball and has the same hash, we reuse
  # it.
  debug("Updating from tarballs")
  for p in buildOrder:
    spec = specs[p]
    tarballHashDir = format("%(workdir)s/TARS/%(architecture)s/store/%(prefix)s/%(hash)s",
                            workdir=workDir,
                            architecture=args.architecture,
                            hash=spec["hash"],
                            prefix=spec["hash"][0:2])
    tarballDir = format("%(workdir)s/TARS/%(architecture)s/",
                        workdir=workDir,
                        architecture=args.architecture,
                        hash=spec["hash"],
                        prefix=spec["hash"][0:2])
    if not exists(tarballHashDir):
      continue
    tarballName = format("%(package)s-%(version)s-%(revision)s.%(architecture)s.tar.gz",
                         package=spec["package"],
                         version=spec["version"],
                         revision=spec["revision"],
                         architecture=args.architecture)
    tarballPath = "%s/%s" % (tarballHashDir, tarballName)
    if not exists(tarballPath):
      continue

    tarballLink = "%s/%s" % (tarballDir, tarballName)
    if not exists(tarballLink):
      print "Found stale tarball in %s, deleting." % tarballPath
      continue
    
    realLink = readlink(tarballLink)
    if not realLink == tarballPath:
      print "%s points to %s but should really point to %s. Removing." % (tarballLink, realLink, tarballPath)
      for x in [tarballLink, realLink, tarballPath]:
        unlink(x)

    # If we arrived here it really means we have the correct tarball.
    # FIXME: check the checksum inside just to make sure.
    # FIXME: in case of error remove and rebuild?
    print "Unpacking %s from %s" % (p, tarballPath)
    err, out = getstatusoutput("cd %s && %s -dc | tar -x %s" % (workDir, gzip(), tarballPath))
    if err:
      print "Error while unpacking."
      print out
      sys.exit(1)
    buildOrder.remove(p)
    
  updateReferenceRepos(args.referenceSources, buildOrder, specs)

  # Build everything, everytime
  for p in buildOrder:
    spec = specs[p]
    # Generate the part which sources the environment for all the dependencies.
    # Notice that we guarantee that a dependency is always sourced before the
    # parts depending on it, but we do not guaranteed anything for the order in
    # which unrelated components are activated.
    dependencies = ""
    dependenciesInit = ""
    for dep in spec.get("requires", []):
      depSpec = specs[dep]
      dependencies += format("source \"$WORK_DIR/%(architecture)s/%(package)s/%(version)s-%(revision)s/etc/profile.d/init.sh\"\n",
                             architecture=args.architecture,
                             package=dep,
                             version=depSpec["version"],
                             revision=depSpec["revision"])
      dependenciesInit += format('echo source $%(bigpackage)s_ROOT/etc/profile.d/init.sh >> \"$INSTALLROOT/etc/profile.d/init.sh\"\n',
                                architecture=args.architecture,
                                package=dep,
                                version=depSpec["version"],
                                revision=depSpec["revision"],
                                bigpackage=dep.upper().replace("-", "_"))
    # Generate the part which creates the environment for the package.
    # This can be either variable set via the "env" keyword in the metadata
    # or paths which get appended via the "append_path" one.
    # By default we append LD_LIBRARY_PATH, PATH and DYLD_LIBRARY_PATH
    # FIXME: do not append variables for Mac on Linux.
    environment = ""
    for (key, value) in spec.get("env", {}).items():
      environment += format("echo 'export %(key)s=%(value)s' >> $INSTALLROOT/etc/profile.d/init.sh\n",
                             architecture=args.architecture,
                             key=key,
                             value=value,
                           )
    basePath = "%s_ROOT" % p.upper().replace("-", "_")
    pathDict = spec.get("append_path", [])

    for pathEntry in pathDict:
      key, value = pathEntry.items()[0] 
      environment += format("echo 'export %(key)s=$%(key)s:%(value)s' >> \"$INSTALLROOT/etc/profile.d/init.sh\"\n",
                             architecture=args.architecture,
                             key=key,
                             package=p,
                             revision=spec["revision"],
                             value=value,
                             version=spec["version"]
                           )

    # Same thing, but prepending the results so that they win against system ones.
    pathDict = [{"LD_LIBRARY_PATH": "$%s/lib" % basePath},
                {"DYLD_LIBRARY_PATH": "$%s/lib" % basePath},
                {"PATH": "$%s/bin" % basePath},
               ]
    pathDict += spec.get("prepend_path", [])

    for pathEntry in pathDict:
      key, value = pathEntry.items()[0] 
      environment += format("echo 'export %(key)s=%(value)s:$%(key)s' >> \"$INSTALLROOT/etc/profile.d/init.sh\"\n",
                             architecture=args.architecture,
                             key=key,
                             package=p,
                             revision=spec["revision"],
                             value=value,
                             version=spec["version"]
                           )

    # The actual build script.
    referenceStatement = ""
    if "reference" in spec:
      referenceStatement = "export GIT_REFERENCE=%s" % spec["reference"]
      
    debug(spec)

    fp = open(dirname(realpath(__file__))+'/build_template.sh', 'r')
    cmd_raw = fp.read()
    fp.close()

    source = spec.get("source", "")
    # Shortend the commit hash in case it's a real commit hash and not simply
    # the tag.
    commit_hash = spec["commit_hash"]
    if spec["tag"] != spec["commit_hash"]:
      commit_hash = spec["commit_hash"][0:10]
    cmd = format(cmd_raw,
                 dependencies=dependencies,
                 dependenciesInit=dependenciesInit,
                 environment=environment,
                 workDir=workDir,
                 configDir=abspath(args.configDir),
                 pkgname=spec["package"],
                 hash=spec["hash"],
                 version=spec["version"],
                 revision=spec["revision"],
                 architecture=args.architecture,
                 jobs=args.jobs,
                 source=source,
                 write_repo=spec.get("write_repo", source),
                 tag=spec["tag"],
                 commit_hash=commit_hash,
                 referenceStatement=referenceStatement)
    scriptName = "%s/SPECS/%s/%s/%s-%s/build.sh" % (workDir,
                                                    args.architecture,
                                                    spec["package"],
                                                    spec["version"], 
                                                    spec["revision"])
    err, out = getstatusoutput("mkdir -p %s" % dirname(scriptName))
    script = open(scriptName, "w") 
    script.write(cmd)
    script.flush()
    script.close()

    print "Building %s@%s" % (spec["package"], spec["version"])
    err = execute("/bin/bash -e -x %s 2>&1" % scriptName)
    if err:
      print "Error while executing %s" % scriptName
      sys.exit(1)
